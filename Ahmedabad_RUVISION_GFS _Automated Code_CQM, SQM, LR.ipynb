{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5722bf-3469-4430-8fbb-98875b4dfbb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "def load_data(pkl_path, excel_df):\n",
    "    X = pd.read_pickle(pkl_path)\n",
    "    Y = excel_df.set_index('DateTime')\n",
    "    Y.index = pd.to_datetime(Y.index)\n",
    "    X.index = Y.index  # force same DateTimeIndex\n",
    "    return X, Y\n",
    "\n",
    "def split_data(X, Y, split_index=3269):\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index+3:]\n",
    "    Y_train, Y_test = Y.iloc[:split_index], Y.iloc[split_index+3:]\n",
    "    # ✅ Keep DateTimeIndex\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def binary_glm(X_train, Y_train):\n",
    "    yb_train = (Y_train > 0).astype(int)\n",
    "    glm = sm.GLM(yb_train, sm.add_constant(X_train), family=sm.families.Binomial()).fit()\n",
    "    yfit_train = glm.predict(sm.add_constant(X_train))\n",
    "    return yfit_train\n",
    "\n",
    "def quantile_regression(X, Y, q):\n",
    "    mod = sm.QuantReg(Y, sm.add_constant(X)).fit(q=q)\n",
    "    return mod.params\n",
    "\n",
    "def reconstruct_rain(X, coefs):\n",
    "    return X @ coefs[1:] + coefs[0]\n",
    "\n",
    "def cqm_pipeline(X_train, Y_train, X_test, thresholds):\n",
    "    yfit_train = binary_glm(X_train, Y_train)\n",
    "    coefs2 = {}\n",
    "    rain_final = {}\n",
    "\n",
    "    for label, t in thresholds.items():\n",
    "        q_val = float(label.replace('p', '')) / 100\n",
    "        mask1 = yfit_train > t\n",
    "        X1, Y1 = X_train[mask1], Y_train[mask1]\n",
    "        if X1.empty or Y1.empty:\n",
    "            continue\n",
    "        coef1 = quantile_regression(X1, Y1, q_val)\n",
    "        rain1 = reconstruct_rain(X1, coef1)\n",
    "        mask2 = rain1 > 0\n",
    "        X2, Y2 = X1[mask2], Y1[mask2]\n",
    "        if X2.empty or Y2.empty:\n",
    "            continue\n",
    "        coef2 = quantile_regression(X2, Y2, q_val)\n",
    "        coefs2[label] = coef2\n",
    "        rain_test = reconstruct_rain(X_test, coef2)\n",
    "        rain_final[label] = np.maximum(rain_test, 0)\n",
    "\n",
    "    return coefs2, rain_final\n",
    "\n",
    "def compute_cqvss(y_true, y_pred_model, y_pred_ref, q):\n",
    "    errors_m = y_true - y_pred_model\n",
    "    errors_r = y_true - y_pred_ref\n",
    "    ql_m = np.mean(np.maximum(q * errors_m, (q - 1) * errors_m))\n",
    "    ql_r = np.mean(np.maximum(q * errors_r, (q - 1) * errors_r))\n",
    "    return 1 - (ql_m / ql_r) if ql_r != 0 else np.nan\n",
    "\n",
    "# === CONFIG ===\n",
    "\n",
    "pca_folder = r'D:\\D\\Ruvision\\GFS\\Pickle format\\PKL'\n",
    "obs_excel = pd.read_excel(\n",
    "    'C:/Users/Angshudeep Majumdar/Documents/Angshudeep Lappy/Ruvision/IMD_2015-2024_Daily Data_0.25 resolution Rain_GFS.xlsx'\n",
    ")\n",
    "output_base = r'D:/D/Ruvision/plots/GFS/GLM'\n",
    "\n",
    "thresholds = {'80p': 0.2, '85p': 0.15, '90p': 0.1, '95p': 0.05, '99p': 0.01}\n",
    "quantiles = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "all_conf_matrices = []  # To collect all confusion matrices\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "\n",
    "for pkl in glob.glob(os.path.join(pca_folder, '*.pkl')):\n",
    "    var_comb = os.path.basename(pkl).split('transformed_dataX_')[1].split('.pkl')[0]\n",
    "    out_dir = os.path.join(output_base, var_comb)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # === Load data ===\n",
    "    X, Y_df = load_data(pkl, obs_excel)\n",
    "    Y = Y_df['Prec_23.0_72.5']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X, Y)\n",
    "\n",
    "    # === CQM ===\n",
    "    coefs2, rain_final = cqm_pipeline(X_train, Y_train, X_test, thresholds)\n",
    "    \n",
    "    # === SQM ===\n",
    "    sqm_models = []\n",
    "    for q in quantiles:\n",
    "        mod = sm.QuantReg(Y_train, sm.add_constant(X_train)).fit(q=q, max_iter=5000)\n",
    "        sqm_models.append(mod)\n",
    "\n",
    "    sqm_final = {}\n",
    "    for i, q in enumerate(quantiles):\n",
    "        rain_q = sqm_models[i].predict(sm.add_constant(X_test))\n",
    "        rain_q = np.maximum(rain_q, 0)\n",
    "        sqm_final[f\"{int(q*100)}p\"] = pd.Series(rain_q, index=X_test.index)\n",
    "\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    lr = LinearRegression().fit(X_train, Y_train)\n",
    "    pred_lr_all = lr.predict(X_test)\n",
    "    pred_lr_all = pd.Series(pred_lr_all, index=X_test.index)\n",
    "\n",
    "    # === JJAS ===\n",
    "    jjas_start = pd.Timestamp('2024-06-02')\n",
    "    jjas_end = pd.Timestamp('2024-09-28')\n",
    "    mask_jjas = (Y_test.index >= jjas_start) & (Y_test.index <= jjas_end)\n",
    "    Y_jjas = Y_test[mask_jjas]\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label in sqm_final:\n",
    "            sqm_final_jjas[q_label] = sqm_final[q_label][mask_jjas]\n",
    "   \n",
    "    pred_lr_jjas = pred_lr_all[mask_jjas]\n",
    "    test_index = Y_test.index\n",
    "\n",
    "    rain_final_jjas = {k: pd.Series(v, index=X_test.index)[mask_jjas] for k, v in rain_final.items()}\n",
    "\n",
    "    threshold_value = np.percentile(Y_jjas, 95)\n",
    "    y_true = np.array(Y_jjas)\n",
    "    y_pred_ref = np.array(pred_lr_jjas)\n",
    "\n",
    "    results = []\n",
    "    reports=[]\n",
    "\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q * 100)}p\"\n",
    "        if q_label not in rain_final_jjas or q_label not in sqm_final_jjas:\n",
    "            continue\n",
    "\n",
    "        y_pred_cqm = rain_final_jjas[q_label].values\n",
    "        y_pred_sqm = sqm_final_jjas[q_label].values\n",
    "        obs_bin = y_true > threshold_value\n",
    "        pred_bin_cqm = y_pred_cqm > threshold_value\n",
    "        pred_bin_sqm = y_pred_sqm > threshold_value\n",
    "        pred_bin_lr = y_pred_ref > threshold_value\n",
    "\n",
    "        H = np.sum((obs_bin == 1) & (pred_bin_cqm == 1))\n",
    "        M = np.sum((obs_bin == 1) & (pred_bin_cqm == 0))\n",
    "        FA = np.sum((obs_bin == 0) & (pred_bin_cqm == 1))\n",
    "        CN = np.sum((obs_bin == 0) & (pred_bin_cqm == 0))\n",
    "\n",
    "        POD = H / (H + M) if (H + M) > 0 else np.nan\n",
    "        FAR = FA / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        Accuracy = (H + CN) / (H + M + FA + CN) if (H + M + FA + CN) > 0 else np.nan\n",
    "        Precision = H / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        F1 = 2 * (Precision * POD) / (Precision + POD) if (Precision + POD) > 0 else np.nan\n",
    "        TS = H / (H + M + FA) if (H + M + FA) > 0 else np.nan\n",
    "        BIAS = (H + FA) / (H + M) if (H + M) > 0 else np.nan\n",
    "        denom = ((H + M) * (M + CN)) + ((H + FA) * (FA + CN))\n",
    "        HSS = (2 * (H * CN - FA * M)) / denom if denom != 0 else np.nan\n",
    "        corr, _ = pearsonr(y_true, y_pred_cqm)\n",
    "        cqvss = compute_cqvss(y_true, y_pred_cqm, y_pred_ref, q)\n",
    "\n",
    "        H_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 1))\n",
    "        M_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 0))\n",
    "        FA_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 1))\n",
    "        CN_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 0))\n",
    "        POD_LR = H_LR / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        FAR_LR = FA_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        Accuracy_LR = (H_LR + CN_LR) / (H_LR + M_LR + FA_LR + CN_LR) if (H_LR + M_LR + FA_LR + CN_LR) > 0 else np.nan\n",
    "        Precision_LR = H_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        F1_LR = 2 * (Precision_LR * H_LR) / (Precision_LR + H_LR) if (Precision_LR + H_LR) > 0 else np.nan\n",
    "        TS_LR = H_LR / (H_LR + M_LR + FA_LR) if (H_LR + M_LR + FA_LR) > 0 else np.nan\n",
    "        BIAS_LR = (H_LR + FA_LR) / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        corr_LR, _ = pearsonr(y_true, y_pred_ref)\n",
    "        \n",
    "        H_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 1))\n",
    "        M_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 0))\n",
    "        FA_SQM = np.sum((obs_bin == 0) & (pred_bin_sqm == 1))\n",
    "        CN_SQM= np.sum((obs_bin == 0) & (pred_bin_sqm == 0))\n",
    "        POD_SQM = H_SQM / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        FAR_SQM = FA_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        Accuracy_SQM = (H_SQM + CN_SQM) / (H_SQM + M_SQM + FA_SQM + CN_SQM) if (H_SQM + M_SQM + FA_SQM + CN_SQM) > 0 else np.nan\n",
    "        Precision_SQM = H_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        F1_SQM = 2 * (Precision_SQM * H_SQM) / (Precision_SQM + H_SQM) if (Precision_SQM + H_SQM) > 0 else np.nan\n",
    "        TS_SQM = H_SQM / (H_SQM + M_SQM + FA_SQM) if (H_SQM + M_SQM + FA_SQM) > 0 else np.nan\n",
    "        BIAS_SQM = (H_SQM + FA_SQM) / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        denom_SQM = ((H_SQM + M_SQM) * (M_SQM + CN_SQM)) + ((H_SQM + FA_SQM) * (FA_SQM + CN_SQM))\n",
    "        HSS_SQM = (2 * (H_SQM * CN_SQM - FA_SQM * M_SQM)) / denom_SQM if denom_SQM != 0 else np.nan\n",
    "        corr_sqm, _ = pearsonr(y_true, y_pred_sqm)\n",
    "        cqvss_sqm = compute_cqvss(y_true, y_pred_sqm, y_pred_ref, q)\n",
    "\n",
    "        results.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H, 'Misses_CQM': M, 'False Alarms_CQM': FA, 'Correct Negatives_CQM': CN,\n",
    "            'Correlation_CQM': round(corr, 3),\n",
    "            'Hit Rate_CQM': round(POD, 3),\n",
    "            'False Alarm Ratio_CQM': round(FAR, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'F1 Score_CQM': round(F1, 3),\n",
    "            'Threat Score_CQM': round(TS, 3),\n",
    "            'Bias Score_CQM': round(BIAS, 3),\n",
    "            'Heidke Skill Score_CQM': round(HSS, 3),\n",
    "            'CQVSS_CQM': round(cqvss, 3),\n",
    "            'Hit Rate_LR': round(POD_LR, 3),\n",
    "            'False Alarm Ratio_LR': round(FAR_LR, 3),\n",
    "            'Accuracy_LR': round(Accuracy_LR, 3),\n",
    "            'Precision_LR': round(Precision_LR, 3),\n",
    "            'F1 Score_LR': round(F1_LR, 3),\n",
    "            'Threat Score_LR': round(TS_LR, 3),\n",
    "            'Bias_LR': round(BIAS_LR, 3),\n",
    "            'Correlation_LR':round(corr_LR,3),\n",
    "            'Hits_SQM': H_SQM, 'Misses_SQM': M_SQM, 'False Alarms_SQM': FA_SQM,\n",
    "            'Correlation_SQM': round(corr_sqm, 3),\n",
    "            'Hit Rate_SQM': round(POD_SQM, 3),\n",
    "            'False Alarm Ratio_SQM': round(FAR_SQM, 3),\n",
    "            'Accuracy_SQM': round(Accuracy_SQM, 3),\n",
    "            'Precision_SQM': round(Precision_SQM, 3),\n",
    "            'F1 Score_SQM': round(F1_SQM, 3),\n",
    "            'Threat Score_SQM': round(TS_SQM, 3),\n",
    "            'Bias_SQM': round(BIAS_SQM, 3),\n",
    "            'Heidke Skill Score_SQM': round(HSS_SQM, 3),\n",
    "            'SQVSS_SQM': round(cqvss_sqm, 3)\n",
    "        })\n",
    "        reports.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H,\n",
    "            'Misses_CQM': M,\n",
    "            'False Alarms_CQM': FA,\n",
    "            'Correct Negatives_CQM': CN,\n",
    "            'Recall_CQM': round(POD, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'F1 Score_CQM': round(F1, 3)\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(results).to_excel(os.path.join(out_dir, 'contingency_matrix.xlsx'), index=False)\n",
    "\n",
    "    conf_matrix = pd.DataFrame([\n",
    "        {\n",
    "            'Variable_Combination': var_comb,\n",
    "            **r\n",
    "        } for r in reports\n",
    "    ])\n",
    "    all_conf_matrices.append(conf_matrix)\n",
    "\n",
    "    # === SAVE FINAL CONCATENATED CONFUSION MATRIX ===\n",
    "\n",
    "    if all_conf_matrices:\n",
    "        final_df = pd.concat(all_conf_matrices, ignore_index=True)\n",
    "        final_df.to_excel(r'C:\\Users\\Angshudeep Majumdar\\Downloads\\all_confusion_matrices.xlsx', index=False)\n",
    "\n",
    "    # === Plots stay same, but now use sqm_final_jjas ===\n",
    "\n",
    "    # === CQM Plots ===\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in rain_final: continue\n",
    "        cqm_jjas = pd.Series(rain_final[q_label], index=test_index)[mask_jjas]\n",
    "        r, _ = pearsonr(Y_jjas, cqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, cqm_jjas))\n",
    "        axs[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs[i].plot(cqm_jjas.index, cqm_jjas, label=f'CQM Q{q}', color='red')\n",
    "        axs[i].set_title(f'CQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "        axs[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'GLM based CQR Model Experiment | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.savefig(os.path.join(out_dir, f'CQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # === SQM Plots ===\n",
    "    fig2, axs2 = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in sqm_final_jjas: continue\n",
    "        sqm_jjas = sqm_final_jjas[q_label]\n",
    "        r, _ = pearsonr(Y_jjas, sqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, sqm_jjas))\n",
    "        axs2[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs2[i].plot(sqm_jjas.index, sqm_jjas, label=f'SQM Q{q}', color='green')\n",
    "        axs2[i].set_title(f'SQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs2[i].tick_params(axis='x', rotation=45)\n",
    "        axs2[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'SQM Prediction | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig2.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig2.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig2.savefig(os.path.join(out_dir, f'SQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # === Skill Score Plots ===\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    x_labels = [f\"{int(q)}p\" for q in metrics_df['Quantile'] * 100]\n",
    "\n",
    "    fig3, axs3 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs3[0].bar(x_labels, metrics_df['Hit Rate_CQM'], color='red'); axs3[0].set_title('Hit Rate (POD)')\n",
    "    axs3[1].bar(x_labels, metrics_df['False Alarm Ratio_CQM'], color='orange'); axs3[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs3[2].bar(x_labels, metrics_df['Threat Score_CQM'], color='blue'); axs3[2].set_title('Threat Score (TS)')\n",
    "    axs3[3].bar(x_labels, metrics_df['Bias Score_CQM'], color='purple'); axs3[3].set_title('Bias Score')\n",
    "    axs3[4].bar(x_labels, metrics_df['Heidke Skill Score_CQM'], color='green'); axs3[4].set_title('HSS')\n",
    "    axs3[5].bar(x_labels, metrics_df['CQVSS_CQM'], color='pink'); axs3[5].set_title('CQVSS')\n",
    "    fig3.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_GLM based CQR Model Experiment', fontsize=16)\n",
    "    fig3.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig3.savefig(os.path.join(out_dir, f'CQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig3)\n",
    "\n",
    "    fig4, axs4 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs4[0].bar(x_labels, metrics_df['Hit Rate_SQM'], color='red'); axs4[0].set_title('Hit Rate (POD)')\n",
    "    axs4[1].bar(x_labels, metrics_df['False Alarm Ratio_SQM'], color='orange'); axs4[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs4[2].bar(x_labels, metrics_df['Threat Score_SQM'], color='blue'); axs4[2].set_title('Threat Score (TS)')\n",
    "    axs4[3].bar(x_labels, metrics_df['Bias_SQM'], color='purple'); axs4[3].set_title('Bias Score')\n",
    "    axs4[4].bar(x_labels, metrics_df['Heidke Skill Score_SQM'], color='green'); axs4[4].set_title('HSS')\n",
    "    axs4[5].bar(x_labels, metrics_df['SQVSS_SQM'], color='pink'); axs4[5].set_title('SQVSS')\n",
    "    fig4.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_SQM', fontsize=16)\n",
    "    fig4.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig4.savefig(os.path.join(out_dir, f'SQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig4)\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    fig5, ax5 = plt.subplots(figsize=(15, 6))\n",
    "    r_lr, _ = pearsonr(Y_jjas, pred_lr_jjas)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(Y_jjas, pred_lr_jjas))\n",
    "    ax5.plot(Y_jjas.index, Y_jjas, label='Observed', color='blue')\n",
    "    ax5.plot(pred_lr_jjas.index, pred_lr_jjas, label='Linear Regression', color='black')\n",
    "    ax5.set_title(f'Linear Regression | {var_comb} | JJAS | r={r_lr:.2f} | RMSE={rmse_lr:.2f}', fontsize=14)\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'Linear Regression | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig5.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig5.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig5.savefig(os.path.join(out_dir, f'LinearRegression_{var_comb}_JJAS.png'))\n",
    "    plt.close(fig5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1900bc53-351c-46da-8cf5-49d007e1c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "def load_data(pkl_path, excel_df):\n",
    "    X = pd.read_pickle(pkl_path)\n",
    "    Y = excel_df.set_index('DateTime')\n",
    "    Y.index = pd.to_datetime(Y.index)\n",
    "    X.index = Y.index  # force same DateTimeIndex\n",
    "    return X, Y\n",
    "\n",
    "def split_data(X, Y, split_index=3269):\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index+3:]\n",
    "    Y_train, Y_test = Y.iloc[:split_index], Y.iloc[split_index+3:]\n",
    "    # ✅ Keep DateTimeIndex\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def binary_logistic(X_train, Y_train):\n",
    "    yb_train = (Y_train > 0).astype(int)\n",
    "    logreg = LogisticRegression(max_iter=5000).fit(X_train, yb_train)\n",
    "    yfit_train = logreg.predict_proba(X_train)[:, 1]\n",
    "    return yfit_train\n",
    "\n",
    "def quantile_regression(X, Y, q):\n",
    "    mod = sm.QuantReg(Y, sm.add_constant(X)).fit(q=q)\n",
    "    return mod.params\n",
    "\n",
    "def reconstruct_rain(X, coefs):\n",
    "    return X @ coefs[1:] + coefs[0]\n",
    "\n",
    "def cqm_pipeline(X_train, Y_train, X_test, thresholds):\n",
    "    yfit_train = binary_logistic(X_train, Y_train)\n",
    "    coefs2 = {}\n",
    "    rain_final = {}\n",
    "\n",
    "    for label, t in thresholds.items():\n",
    "        q_val = float(label.replace('p', '')) / 100\n",
    "        mask1 = yfit_train > t\n",
    "        X1, Y1 = X_train[mask1], Y_train[mask1]\n",
    "        if X1.empty or Y1.empty:\n",
    "            continue\n",
    "        coef1 = quantile_regression(X1, Y1, q_val)\n",
    "        rain1 = reconstruct_rain(X1, coef1)\n",
    "        mask2 = rain1 > 0\n",
    "        X2, Y2 = X1[mask2], Y1[mask2]\n",
    "        if X2.empty or Y2.empty:\n",
    "            continue\n",
    "        coef2 = quantile_regression(X2, Y2, q_val)\n",
    "        coefs2[label] = coef2\n",
    "        rain_test = reconstruct_rain(X_test, coef2)\n",
    "        rain_final[label] = np.maximum(rain_test, 0)\n",
    "\n",
    "    return coefs2, rain_final\n",
    "\n",
    "def compute_cqvss(y_true, y_pred_model, y_pred_ref, q):\n",
    "    errors_m = y_true - y_pred_model\n",
    "    errors_r = y_true - y_pred_ref\n",
    "    ql_m = np.mean(np.maximum(q * errors_m, (q - 1) * errors_m))\n",
    "    ql_r = np.mean(np.maximum(q * errors_r, (q - 1) * errors_r))\n",
    "    return 1 - (ql_m / ql_r) if ql_r != 0 else np.nan\n",
    "\n",
    "# === CONFIG ===\n",
    "\n",
    "pca_folder = r'D:\\D\\Ruvision\\GFS\\Pickle format\\PKL'\n",
    "obs_excel = pd.read_excel(\n",
    "    'C:/Users/Angshudeep Majumdar/Documents/Angshudeep Lappy/Ruvision/IMD_2015-2024_Daily Data_0.25 resolution Rain_GFS.xlsx'\n",
    ")\n",
    "output_base = r'D:/D/Ruvision/plots/GFS/Logistic_reg'\n",
    "\n",
    "thresholds = {'80p': 0.2, '85p': 0.15, '90p': 0.1, '95p': 0.05, '99p': 0.01}\n",
    "quantiles = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "all_conf_matrices = []  # To collect all confusion matrices\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "\n",
    "for pkl in glob.glob(os.path.join(pca_folder, '*.pkl')):\n",
    "    var_comb = os.path.basename(pkl).split('transformed_dataX_')[1].split('.pkl')[0]\n",
    "    out_dir = os.path.join(output_base, var_comb)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # === Load data ===\n",
    "    X, Y_df = load_data(pkl, obs_excel)\n",
    "    Y = Y_df['Prec_23.0_72.5']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X, Y)\n",
    "\n",
    "    # === CQM ===\n",
    "    coefs2, rain_final = cqm_pipeline(X_train, Y_train, X_test, thresholds)\n",
    "    \n",
    "    # === SQM ===\n",
    "    sqm_models = []\n",
    "    for q in quantiles:\n",
    "        mod = sm.QuantReg(Y_train, sm.add_constant(X_train)).fit(q=q, max_iter=5000)\n",
    "        sqm_models.append(mod)\n",
    "\n",
    "    sqm_final = {}\n",
    "    for i, q in enumerate(quantiles):\n",
    "        rain_q = sqm_models[i].predict(sm.add_constant(X_test))\n",
    "        rain_q = np.maximum(rain_q, 0)\n",
    "        sqm_final[f\"{int(q*100)}p\"] = pd.Series(rain_q, index=X_test.index)\n",
    "\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    lr = LinearRegression().fit(X_train, Y_train)\n",
    "    pred_lr_all = lr.predict(X_test)\n",
    "    pred_lr_all = pd.Series(pred_lr_all, index=X_test.index)\n",
    "\n",
    "    # === JJAS ===\n",
    "    jjas_start = pd.Timestamp('2024-06-02')\n",
    "    jjas_end = pd.Timestamp('2024-09-28')\n",
    "    mask_jjas = (Y_test.index >= jjas_start) & (Y_test.index <= jjas_end)\n",
    "    Y_jjas = Y_test[mask_jjas]\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label in sqm_final:\n",
    "            sqm_final_jjas[q_label] = sqm_final[q_label][mask_jjas]\n",
    "   \n",
    "    pred_lr_jjas = pred_lr_all[mask_jjas]\n",
    "    test_index = Y_test.index\n",
    "\n",
    "    rain_final_jjas = {k: pd.Series(v, index=X_test.index)[mask_jjas] for k, v in rain_final.items()}\n",
    "\n",
    "    threshold_value = np.percentile(Y_jjas, 95)\n",
    "    y_true = np.array(Y_jjas)\n",
    "    y_pred_ref = np.array(pred_lr_jjas)\n",
    "\n",
    "    results = []\n",
    "    reports=[]\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q * 100)}p\"\n",
    "        if q_label not in rain_final_jjas or q_label not in sqm_final_jjas:\n",
    "            continue\n",
    "\n",
    "        y_pred_cqm = rain_final_jjas[q_label].values\n",
    "        y_pred_sqm = sqm_final_jjas[q_label].values\n",
    "        obs_bin = y_true > threshold_value\n",
    "        pred_bin_cqm = y_pred_cqm > threshold_value\n",
    "        pred_bin_sqm = y_pred_sqm > threshold_value\n",
    "        pred_bin_lr = y_pred_ref > threshold_value\n",
    "\n",
    "        H = np.sum((obs_bin == 1) & (pred_bin_cqm == 1))\n",
    "        M = np.sum((obs_bin == 1) & (pred_bin_cqm == 0))\n",
    "        FA = np.sum((obs_bin == 0) & (pred_bin_cqm == 1))\n",
    "        CN = np.sum((obs_bin == 0) & (pred_bin_cqm == 0))\n",
    "\n",
    "        POD = H / (H + M) if (H + M) > 0 else np.nan\n",
    "        FAR = FA / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        Accuracy = (H + CN) / (H + M + FA + CN) if (H + M + FA + CN) > 0 else np.nan\n",
    "        Precision = H / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        F1 = 2 * (Precision * POD) / (Precision + POD) if (Precision + POD) > 0 else np.nan\n",
    "        TS = H / (H + M + FA) if (H + M + FA) > 0 else np.nan\n",
    "        BIAS = (H + FA) / (H + M) if (H + M) > 0 else np.nan\n",
    "        denom = ((H + M) * (M + CN)) + ((H + FA) * (FA + CN))\n",
    "        HSS = (2 * (H * CN - FA * M)) / denom if denom != 0 else np.nan\n",
    "        corr, _ = pearsonr(y_true, y_pred_cqm)\n",
    "        cqvss = compute_cqvss(y_true, y_pred_cqm, y_pred_ref, q)\n",
    "\n",
    "        H_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 1))\n",
    "        M_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 0))\n",
    "        FA_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 1))\n",
    "        CN_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 0))\n",
    "        POD_LR = H_LR / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        FAR_LR = FA_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        Accuracy_LR = (H_LR + CN_LR) / (H_LR + M_LR + FA_LR + CN_LR) if (H_LR + M_LR + FA_LR + CN_LR) > 0 else np.nan\n",
    "        Precision_LR = H_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        F1_LR = 2 * (Precision_LR * H_LR) / (Precision_LR + H_LR) if (Precision_LR + H_LR) > 0 else np.nan\n",
    "        TS_LR = H_LR / (H_LR + M_LR + FA_LR) if (H_LR + M_LR + FA_LR) > 0 else np.nan\n",
    "        BIAS_LR = (H_LR + FA_LR) / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        corr_LR, _ = pearsonr(y_true, y_pred_ref)\n",
    "        \n",
    "        H_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 1))\n",
    "        M_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 0))\n",
    "        FA_SQM = np.sum((obs_bin == 0) & (pred_bin_sqm == 1))\n",
    "        CN_SQM= np.sum((obs_bin == 0) & (pred_bin_sqm == 0))\n",
    "        POD_SQM = H_SQM / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        FAR_SQM = FA_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        Accuracy_SQM = (H_SQM + CN_SQM) / (H_SQM + M_SQM + FA_SQM + CN_SQM) if (H_SQM + M_SQM + FA_SQM + CN_SQM) > 0 else np.nan\n",
    "        Precision_SQM = H_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        F1_SQM = 2 * (Precision_SQM * H_SQM) / (Precision_SQM + H_SQM) if (Precision_SQM + H_SQM) > 0 else np.nan\n",
    "        TS_SQM = H_SQM / (H_SQM + M_SQM + FA_SQM) if (H_SQM + M_SQM + FA_SQM) > 0 else np.nan\n",
    "        BIAS_SQM = (H_SQM + FA_SQM) / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        denom_SQM = ((H_SQM + M_SQM) * (M_SQM + CN_SQM)) + ((H_SQM + FA_SQM) * (FA_SQM + CN_SQM))\n",
    "        HSS_SQM = (2 * (H_SQM * CN_SQM - FA_SQM * M_SQM)) / denom_SQM if denom_SQM != 0 else np.nan\n",
    "        corr_sqm, _ = pearsonr(y_true, y_pred_sqm)\n",
    "        cqvss_sqm = compute_cqvss(y_true, y_pred_sqm, y_pred_ref, q)\n",
    "\n",
    "        results.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H, 'Misses_CQM': M, 'False Alarms_CQM': FA, 'Correct Negatives_CQM': CN,\n",
    "            'Correlation_CQM': round(corr, 3),\n",
    "            'Hit Rate_CQM': round(POD, 3),\n",
    "            'False Alarm Ratio_CQM': round(FAR, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'F1 Score_CQM': round(F1, 3),\n",
    "            'Threat Score_CQM': round(TS, 3),\n",
    "            'Bias Score_CQM': round(BIAS, 3),\n",
    "            'Heidke Skill Score_CQM': round(HSS, 3),\n",
    "            'CQVSS_CQM': round(cqvss, 3),\n",
    "            'Hit Rate_LR': round(POD_LR, 3),\n",
    "            'False Alarm Ratio_LR': round(FAR_LR, 3),\n",
    "            'Accuracy_LR': round(Accuracy_LR, 3),\n",
    "            'Precision_LR': round(Precision_LR, 3),\n",
    "            'F1 Score_LR': round(F1_LR, 3),\n",
    "            'Threat Score_LR': round(TS_LR, 3),\n",
    "            'Bias_LR': round(BIAS_LR, 3),\n",
    "            'Correlation_LR':round(corr_LR,3),\n",
    "            'Hits_SQM': H_SQM, 'Misses_SQM': M_SQM, 'False Alarms_SQM': FA_SQM,\n",
    "            'Correlation_SQM': round(corr_sqm, 3),\n",
    "            'Hit Rate_SQM': round(POD_SQM, 3),\n",
    "            'False Alarm Ratio_SQM': round(FAR_SQM, 3),\n",
    "            'Accuracy_SQM': round(Accuracy_SQM, 3),\n",
    "            'Precision_SQM': round(Precision_SQM, 3),\n",
    "            'F1 Score_SQM': round(F1_SQM, 3),\n",
    "            'Threat Score_SQM': round(TS_SQM, 3),\n",
    "            'Bias_SQM': round(BIAS_SQM, 3),\n",
    "            'Heidke Skill Score_SQM': round(HSS_SQM, 3),\n",
    "            'SQVSS_SQM': round(cqvss_sqm, 3)\n",
    "        })\n",
    "        \n",
    "        reports.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H,\n",
    "            'Misses_CQM': M,\n",
    "            'False Alarms_CQM': FA,\n",
    "            'Correct Negatives_CQM': CN,\n",
    "            'Recall_CQM': round(POD, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'F1 Score_CQM': round(F1, 3)\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(results).to_excel(os.path.join(out_dir, 'contingency_matrix.xlsx'), index=False)\n",
    "\n",
    "    conf_matrix = pd.DataFrame([\n",
    "        {\n",
    "            'Variable_Combination': var_comb,\n",
    "            **r\n",
    "        } for r in reports\n",
    "    ])\n",
    "    all_conf_matrices.append(conf_matrix)\n",
    "    # === SAVE FINAL CONCATENATED CONFUSION MATRIX ===\n",
    "\n",
    "    if all_conf_matrices:\n",
    "        final_df = pd.concat(all_conf_matrices, ignore_index=True)\n",
    "        final_df.to_excel(r'C:\\Users\\Angshudeep Majumdar\\Downloads\\all_confusion_matrices.xlsx', index=False)\n",
    "        \n",
    "    # === Plots stay same, but now use sqm_final_jjas ===\n",
    "\n",
    "    # === CQM Plots ===\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in rain_final: continue\n",
    "        cqm_jjas = pd.Series(rain_final[q_label], index=test_index)[mask_jjas]\n",
    "        r, _ = pearsonr(Y_jjas, cqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, cqm_jjas))\n",
    "        axs[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs[i].plot(cqm_jjas.index, cqm_jjas, label=f'CQM Q{q}', color='red')\n",
    "        axs[i].set_title(f'CQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "        axs[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'LGR based CQR Model Experiment | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.savefig(os.path.join(out_dir, f'CQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # === SQM Plots ===\n",
    "    fig2, axs2 = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in sqm_final_jjas: continue\n",
    "        sqm_jjas = sqm_final_jjas[q_label]\n",
    "        r, _ = pearsonr(Y_jjas, sqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, sqm_jjas))\n",
    "        axs2[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs2[i].plot(sqm_jjas.index, sqm_jjas, label=f'SQM Q{q}', color='green')\n",
    "        axs2[i].set_title(f'SQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs2[i].tick_params(axis='x', rotation=45)\n",
    "        axs2[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'SQM Prediction | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig2.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig2.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig2.savefig(os.path.join(out_dir, f'SQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # === Skill Score Plots ===\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    x_labels = [f\"{int(q)}p\" for q in metrics_df['Quantile'] * 100]\n",
    "\n",
    "    fig3, axs3 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs3[0].bar(x_labels, metrics_df['Hit Rate_CQM'], color='red'); axs3[0].set_title('Hit Rate (POD)')\n",
    "    axs3[1].bar(x_labels, metrics_df['False Alarm Ratio_CQM'], color='orange'); axs3[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs3[2].bar(x_labels, metrics_df['Threat Score_CQM'], color='blue'); axs3[2].set_title('Threat Score (TS)')\n",
    "    axs3[3].bar(x_labels, metrics_df['Bias Score_CQM'], color='purple'); axs3[3].set_title('Bias Score')\n",
    "    axs3[4].bar(x_labels, metrics_df['Heidke Skill Score_CQM'], color='green'); axs3[4].set_title('HSS')\n",
    "    axs3[5].bar(x_labels, metrics_df['CQVSS_CQM'], color='pink'); axs3[5].set_title('CQVSS')\n",
    "    fig3.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_LGR based CQR Model Experiment', fontsize=16)\n",
    "    fig3.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig3.savefig(os.path.join(out_dir, f'CQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig3)\n",
    "\n",
    "    fig4, axs4 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs4[0].bar(x_labels, metrics_df['Hit Rate_SQM'], color='red'); axs4[0].set_title('Hit Rate (POD)')\n",
    "    axs4[1].bar(x_labels, metrics_df['False Alarm Ratio_SQM'], color='orange'); axs4[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs4[2].bar(x_labels, metrics_df['Threat Score_SQM'], color='blue'); axs4[2].set_title('Threat Score (TS)')\n",
    "    axs4[3].bar(x_labels, metrics_df['Bias_SQM'], color='purple'); axs4[3].set_title('Bias Score')\n",
    "    axs4[4].bar(x_labels, metrics_df['Heidke Skill Score_SQM'], color='green'); axs4[4].set_title('HSS')\n",
    "    axs4[5].bar(x_labels, metrics_df['SQVSS_SQM'], color='pink'); axs4[5].set_title('SQVSS')\n",
    "    fig4.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_SQM', fontsize=16)\n",
    "    fig4.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig4.savefig(os.path.join(out_dir, f'SQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig4)\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    fig5, ax5 = plt.subplots(figsize=(15, 6))\n",
    "    r_lr, _ = pearsonr(Y_jjas, pred_lr_jjas)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(Y_jjas, pred_lr_jjas))\n",
    "    ax5.plot(Y_jjas.index, Y_jjas, label='Observed', color='blue')\n",
    "    ax5.plot(pred_lr_jjas.index, pred_lr_jjas, label='Linear Regression', color='black')\n",
    "    ax5.set_title(f'Linear Regression | {var_comb} | JJAS | r={r_lr:.2f} | RMSE={rmse_lr:.2f}', fontsize=14)\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'Linear Regression | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig5.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig5.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig5.savefig(os.path.join(out_dir, f'LinearRegression_{var_comb}_JJAS.png'))\n",
    "    plt.close(fig5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8d7c47-c607-4914-9f82-dc5b595ce2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "def load_data(pkl_path, excel_df):\n",
    "    X = pd.read_pickle(pkl_path)\n",
    "    Y = excel_df.set_index('DateTime')\n",
    "    Y.index = pd.to_datetime(Y.index)\n",
    "    X.index = Y.index  # force same DateTimeIndex\n",
    "    return X, Y\n",
    "\n",
    "def split_data(X, Y, split_index=3269):\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index+3:]\n",
    "    Y_train, Y_test = Y.iloc[:split_index], Y.iloc[split_index+3:]\n",
    "    # ✅ Keep DateTimeIndex\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def binary_rf(X_train, Y_train):\n",
    "    yb_train = (Y_train > 0).astype(int)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, yb_train)\n",
    "    yfit_train = rf.predict_proba(X_train)[:, 1]  # probability P(Y>0)\n",
    "    return yfit_train\n",
    "\n",
    "def quantile_regression(X, Y, q):\n",
    "    mod = sm.QuantReg(Y, sm.add_constant(X)).fit(q=q)\n",
    "    return mod.params\n",
    "\n",
    "def reconstruct_rain(X, coefs):\n",
    "    return X @ coefs[1:] + coefs[0]\n",
    "\n",
    "def cqm_pipeline(X_train, Y_train, X_test, thresholds):\n",
    "    yfit_train = binary_rf(X_train, Y_train)\n",
    "    coefs2 = {}\n",
    "    rain_final = {}\n",
    "\n",
    "    for label, t in thresholds.items():\n",
    "        q_val = float(label.replace('p', '')) / 100\n",
    "        mask1 = yfit_train > t\n",
    "        X1, Y1 = X_train[mask1], Y_train[mask1]\n",
    "        if X1.empty or Y1.empty:\n",
    "            continue\n",
    "        coef1 = quantile_regression(X1, Y1, q_val)\n",
    "        rain1 = reconstruct_rain(X1, coef1)\n",
    "        mask2 = rain1 > 0\n",
    "        X2, Y2 = X1[mask2], Y1[mask2]\n",
    "        if X2.empty or Y2.empty:\n",
    "            continue\n",
    "        coef2 = quantile_regression(X2, Y2, q_val)\n",
    "        coefs2[label] = coef2\n",
    "        rain_test = reconstruct_rain(X_test, coef2)\n",
    "        rain_final[label] = np.maximum(rain_test, 0)\n",
    "\n",
    "    return coefs2, rain_final\n",
    "\n",
    "def compute_cqvss(y_true, y_pred_model, y_pred_ref, q):\n",
    "    errors_m = y_true - y_pred_model\n",
    "    errors_r = y_true - y_pred_ref\n",
    "    ql_m = np.mean(np.maximum(q * errors_m, (q - 1) * errors_m))\n",
    "    ql_r = np.mean(np.maximum(q * errors_r, (q - 1) * errors_r))\n",
    "    return 1 - (ql_m / ql_r) if ql_r != 0 else np.nan\n",
    "\n",
    "# === CONFIG ===\n",
    "\n",
    "pca_folder = r'D:\\D\\Ruvision\\GFS\\Pickle format\\PKL'\n",
    "obs_excel = pd.read_excel(\n",
    "    'C:/Users/Angshudeep Majumdar/Documents/Angshudeep Lappy/Ruvision/IMD_2015-2024_Daily Data_0.25 resolution Rain_GFS.xlsx'\n",
    ")\n",
    "output_base = r'D:/D/Ruvision/plots/GFS/Random_Forest'\n",
    "\n",
    "thresholds = {'80p': 0.2, '85p': 0.15, '90p': 0.1, '95p': 0.05, '99p': 0.01}\n",
    "quantiles = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "all_conf_matrices=[]\n",
    "# === MAIN LOOP ===\n",
    "\n",
    "for pkl in glob.glob(os.path.join(pca_folder, '*.pkl')):\n",
    "    var_comb = os.path.basename(pkl).split('transformed_dataX_')[1].split('.pkl')[0]\n",
    "    out_dir = os.path.join(output_base, var_comb)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # === Load data ===\n",
    "    X, Y_df = load_data(pkl, obs_excel)\n",
    "    Y = Y_df['Prec_23.0_72.5']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X, Y)\n",
    "\n",
    "    # === CQM ===\n",
    "    coefs2, rain_final = cqm_pipeline(X_train, Y_train, X_test, thresholds)\n",
    "    \n",
    "    # === SQM ===\n",
    "    sqm_models = []\n",
    "    for q in quantiles:\n",
    "        mod = sm.QuantReg(Y_train, sm.add_constant(X_train)).fit(q=q, max_iter=5000)\n",
    "        sqm_models.append(mod)\n",
    "\n",
    "    sqm_final = {}\n",
    "    for i, q in enumerate(quantiles):\n",
    "        rain_q = sqm_models[i].predict(sm.add_constant(X_test))\n",
    "        rain_q = np.maximum(rain_q, 0)\n",
    "        sqm_final[f\"{int(q*100)}p\"] = pd.Series(rain_q, index=X_test.index)\n",
    "\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    lr = LinearRegression().fit(X_train, Y_train)\n",
    "    pred_lr_all = lr.predict(X_test)\n",
    "    pred_lr_all = pd.Series(pred_lr_all, index=X_test.index)\n",
    "\n",
    "    # === JJAS ===\n",
    "    jjas_start = pd.Timestamp('2024-06-02')\n",
    "    jjas_end = pd.Timestamp('2024-09-28')\n",
    "    mask_jjas = (Y_test.index >= jjas_start) & (Y_test.index <= jjas_end)\n",
    "    Y_jjas = Y_test[mask_jjas]\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label in sqm_final:\n",
    "            sqm_final_jjas[q_label] = sqm_final[q_label][mask_jjas]\n",
    "   \n",
    "    pred_lr_jjas = pred_lr_all[mask_jjas]\n",
    "    test_index = Y_test.index\n",
    "\n",
    "    rain_final_jjas = {k: pd.Series(v, index=X_test.index)[mask_jjas] for k, v in rain_final.items()}\n",
    "\n",
    "    threshold_value = np.percentile(Y_jjas, 95)\n",
    "    y_true = np.array(Y_jjas)\n",
    "    y_pred_ref = np.array(pred_lr_jjas)\n",
    "\n",
    "    results = []\n",
    "    reports=[]\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q * 100)}p\"\n",
    "        if q_label not in rain_final_jjas or q_label not in sqm_final_jjas:\n",
    "            continue\n",
    "\n",
    "        y_pred_cqm = rain_final_jjas[q_label].values\n",
    "        y_pred_sqm = sqm_final_jjas[q_label].values\n",
    "        obs_bin = y_true > threshold_value\n",
    "        pred_bin_cqm = y_pred_cqm > threshold_value\n",
    "        pred_bin_sqm = y_pred_sqm > threshold_value\n",
    "        pred_bin_lr = y_pred_ref > threshold_value\n",
    "\n",
    "        H = np.sum((obs_bin == 1) & (pred_bin_cqm == 1))\n",
    "        M = np.sum((obs_bin == 1) & (pred_bin_cqm == 0))\n",
    "        FA = np.sum((obs_bin == 0) & (pred_bin_cqm == 1))\n",
    "        CN = np.sum((obs_bin == 0) & (pred_bin_cqm == 0))\n",
    "\n",
    "        POD = H / (H + M) if (H + M) > 0 else np.nan\n",
    "        FAR = FA / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        Accuracy = (H + CN) / (H + M + FA + CN) if (H + M + FA + CN) > 0 else np.nan\n",
    "        Precision = H / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        F1 = 2 * (Precision * POD) / (Precision + POD) if (Precision + POD) > 0 else np.nan\n",
    "        TS = H / (H + M + FA) if (H + M + FA) > 0 else np.nan\n",
    "        BIAS = (H + FA) / (H + M) if (H + M) > 0 else np.nan\n",
    "        denom = ((H + M) * (M + CN)) + ((H + FA) * (FA + CN))\n",
    "        HSS = (2 * (H * CN - FA * M)) / denom if denom != 0 else np.nan\n",
    "        corr, _ = pearsonr(y_true, y_pred_cqm)\n",
    "        cqvss = compute_cqvss(y_true, y_pred_cqm, y_pred_ref, q)\n",
    "\n",
    "        H_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 1))\n",
    "        M_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 0))\n",
    "        FA_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 1))\n",
    "        CN_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 0))\n",
    "        POD_LR = H_LR / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        FAR_LR = FA_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        Accuracy_LR = (H_LR + CN_LR) / (H_LR + M_LR + FA_LR + CN_LR) if (H_LR + M_LR + FA_LR + CN_LR) > 0 else np.nan\n",
    "        Precision_LR = H_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        F1_LR = 2 * (Precision_LR * H_LR) / (Precision_LR + H_LR) if (Precision_LR + H_LR) > 0 else np.nan\n",
    "        TS_LR = H_LR / (H_LR + M_LR + FA_LR) if (H_LR + M_LR + FA_LR) > 0 else np.nan\n",
    "        BIAS_LR = (H_LR + FA_LR) / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        corr_LR, _ = pearsonr(y_true, y_pred_ref)\n",
    "        \n",
    "        H_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 1))\n",
    "        M_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 0))\n",
    "        FA_SQM = np.sum((obs_bin == 0) & (pred_bin_sqm == 1))\n",
    "        CN_SQM= np.sum((obs_bin == 0) & (pred_bin_sqm == 0))\n",
    "        POD_SQM = H_SQM / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        FAR_SQM = FA_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        Accuracy_SQM = (H_SQM + CN_SQM) / (H_SQM + M_SQM + FA_SQM + CN_SQM) if (H_SQM + M_SQM + FA_SQM + CN_SQM) > 0 else np.nan\n",
    "        Precision_SQM = H_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        F1_SQM = 2 * (Precision_SQM * H_SQM) / (Precision_SQM + H_SQM) if (Precision_SQM + H_SQM) > 0 else np.nan\n",
    "        TS_SQM = H_SQM / (H_SQM + M_SQM + FA_SQM) if (H_SQM + M_SQM + FA_SQM) > 0 else np.nan\n",
    "        BIAS_SQM = (H_SQM + FA_SQM) / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        denom_SQM = ((H_SQM + M_SQM) * (M_SQM + CN_SQM)) + ((H_SQM + FA_SQM) * (FA_SQM + CN_SQM))\n",
    "        HSS_SQM = (2 * (H_SQM * CN_SQM - FA_SQM * M_SQM)) / denom_SQM if denom_SQM != 0 else np.nan\n",
    "        corr_sqm, _ = pearsonr(y_true, y_pred_sqm)\n",
    "        cqvss_sqm = compute_cqvss(y_true, y_pred_sqm, y_pred_ref, q)\n",
    "\n",
    "        results.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H, 'Misses_CQM': M, 'False Alarms_CQM': FA, 'Correct Negatives_CQM': CN,\n",
    "            'Correlation_CQM': round(corr, 3),\n",
    "            'Hit Rate_CQM': round(POD, 3),\n",
    "            'False Alarm Ratio_CQM': round(FAR, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'F1 Score_CQM': round(F1, 3),\n",
    "            'Threat Score_CQM': round(TS, 3),\n",
    "            'Bias Score_CQM': round(BIAS, 3),\n",
    "            'Heidke Skill Score_CQM': round(HSS, 3),\n",
    "            'CQVSS_CQM': round(cqvss, 3),\n",
    "            'Hit Rate_LR': round(POD_LR, 3),\n",
    "            'False Alarm Ratio_LR': round(FAR_LR, 3),\n",
    "            'Accuracy_LR': round(Accuracy_LR, 3),\n",
    "            'Precision_LR': round(Precision_LR, 3),\n",
    "            'F1 Score_LR': round(F1_LR, 3),\n",
    "            'Threat Score_LR': round(TS_LR, 3),\n",
    "            'Bias_LR': round(BIAS_LR, 3),\n",
    "            'Correlation_LR':round(corr_LR,3),\n",
    "            'Hits_SQM': H_SQM, 'Misses_SQM': M_SQM, 'False Alarms_SQM': FA_SQM,\n",
    "            'Correlation_SQM': round(corr_sqm, 3),\n",
    "            'Hit Rate_SQM': round(POD_SQM, 3),\n",
    "            'False Alarm Ratio_SQM': round(FAR_SQM, 3),\n",
    "            'Accuracy_SQM': round(Accuracy_SQM, 3),\n",
    "            'Precision_SQM': round(Precision_SQM, 3),\n",
    "            'F1 Score_SQM': round(F1_SQM, 3),\n",
    "            'Threat Score_SQM': round(TS_SQM, 3),\n",
    "            'Bias_SQM': round(BIAS_SQM, 3),\n",
    "            'Heidke Skill Score_SQM': round(HSS_SQM, 3),\n",
    "            'SQVSS_SQM': round(cqvss_sqm, 3)\n",
    "        })\n",
    "        reports.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H,\n",
    "            'Misses_CQM': M,\n",
    "            'False Alarms_CQM': FA,\n",
    "            'Correct Negatives_CQM': CN,\n",
    "            'Recall_CQM': round(POD, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'F1 Score_CQM': round(F1, 3)\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(results).to_excel(os.path.join(out_dir, 'contingency_matrix.xlsx'), index=False)\n",
    "\n",
    "    conf_matrix = pd.DataFrame([\n",
    "        {\n",
    "            'Variable_Combination': var_comb,\n",
    "            **r\n",
    "        } for r in reports\n",
    "    ])\n",
    "    all_conf_matrices.append(conf_matrix)\n",
    "    # === SAVE FINAL CONCATENATED CONFUSION MATRIX ===\n",
    "\n",
    "    if all_conf_matrices:\n",
    "        final_df = pd.concat(all_conf_matrices, ignore_index=True)\n",
    "        final_df.to_excel(r'C:\\Users\\Angshudeep Majumdar\\Downloads\\all_confusion_matrices.xlsx', index=False)\n",
    "\n",
    "    # === Plots stay same, but now use sqm_final_jjas ===\n",
    "\n",
    "    # === CQM Plots ===\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in rain_final: continue\n",
    "        cqm_jjas = pd.Series(rain_final[q_label], index=test_index)[mask_jjas]\n",
    "        r, _ = pearsonr(Y_jjas, cqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, cqm_jjas))\n",
    "        axs[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs[i].plot(cqm_jjas.index, cqm_jjas, label=f'CQM Q{q}', color='red')\n",
    "        axs[i].set_title(f'CQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "        axs[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'RF based CQR Model Experiment | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.savefig(os.path.join(out_dir, f'CQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # === SQM Plots ===\n",
    "    fig2, axs2 = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in sqm_final_jjas: continue\n",
    "        sqm_jjas = sqm_final_jjas[q_label]\n",
    "        r, _ = pearsonr(Y_jjas, sqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, sqm_jjas))\n",
    "        axs2[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs2[i].plot(sqm_jjas.index, sqm_jjas, label=f'SQM Q{q}', color='green')\n",
    "        axs2[i].set_title(f'SQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs2[i].tick_params(axis='x', rotation=45)\n",
    "        axs2[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'SQM Prediction | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig2.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig2.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig2.savefig(os.path.join(out_dir, f'SQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # === Skill Score Plots ===\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    x_labels = [f\"{int(q)}p\" for q in metrics_df['Quantile'] * 100]\n",
    "\n",
    "    fig3, axs3 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs3[0].bar(x_labels, metrics_df['Hit Rate_CQM'], color='red'); axs3[0].set_title('Hit Rate (POD)')\n",
    "    axs3[1].bar(x_labels, metrics_df['False Alarm Ratio_CQM'], color='orange'); axs3[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs3[2].bar(x_labels, metrics_df['Threat Score_CQM'], color='blue'); axs3[2].set_title('Threat Score (TS)')\n",
    "    axs3[3].bar(x_labels, metrics_df['Bias Score_CQM'], color='purple'); axs3[3].set_title('Bias Score')\n",
    "    axs3[4].bar(x_labels, metrics_df['Heidke Skill Score_CQM'], color='green'); axs3[4].set_title('HSS')\n",
    "    axs3[5].bar(x_labels, metrics_df['CQVSS_CQM'], color='pink'); axs3[5].set_title('CQVSS')\n",
    "    fig3.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_RF based CQR Model Experiment', fontsize=16)\n",
    "    fig3.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig3.savefig(os.path.join(out_dir, f'CQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig3)\n",
    "\n",
    "    fig4, axs4 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs4[0].bar(x_labels, metrics_df['Hit Rate_SQM'], color='red'); axs4[0].set_title('Hit Rate (POD)')\n",
    "    axs4[1].bar(x_labels, metrics_df['False Alarm Ratio_SQM'], color='orange'); axs4[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs4[2].bar(x_labels, metrics_df['Threat Score_SQM'], color='blue'); axs4[2].set_title('Threat Score (TS)')\n",
    "    axs4[3].bar(x_labels, metrics_df['Bias_SQM'], color='purple'); axs4[3].set_title('Bias Score')\n",
    "    axs4[4].bar(x_labels, metrics_df['Heidke Skill Score_SQM'], color='green'); axs4[4].set_title('HSS')\n",
    "    axs4[5].bar(x_labels, metrics_df['SQVSS_SQM'], color='pink'); axs4[5].set_title('SQVSS')\n",
    "    fig4.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_SQM', fontsize=16)\n",
    "    fig4.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig4.savefig(os.path.join(out_dir, f'SQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig4)\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    fig5, ax5 = plt.subplots(figsize=(15, 6))\n",
    "    r_lr, _ = pearsonr(Y_jjas, pred_lr_jjas)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(Y_jjas, pred_lr_jjas))\n",
    "    ax5.plot(Y_jjas.index, Y_jjas, label='Observed', color='blue')\n",
    "    ax5.plot(pred_lr_jjas.index, pred_lr_jjas, label='Linear Regression', color='black')\n",
    "    ax5.set_title(f'Linear Regression | {var_comb} | JJAS | r={r_lr:.2f} | RMSE={rmse_lr:.2f}', fontsize=14)\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'Linear Regression | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig5.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig5.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig5.savefig(os.path.join(out_dir, f'LinearRegression_{var_comb}_JJAS.png'))\n",
    "    plt.close(fig5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b7a7bc-b794-421d-b88f-f4f806122b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:33:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:33:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:33:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:33:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "C:\\Users\\Angshudeep Majumdar\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:33:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "def load_data(pkl_path, excel_df):\n",
    "    X = pd.read_pickle(pkl_path)\n",
    "    Y = excel_df.set_index('DateTime')\n",
    "    Y.index = pd.to_datetime(Y.index)\n",
    "    X.index = Y.index  # force same DateTimeIndex\n",
    "    return X, Y\n",
    "\n",
    "def split_data(X, Y, split_index=3269):\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index+3:]\n",
    "    Y_train, Y_test = Y.iloc[:split_index], Y.iloc[split_index+3:]\n",
    "    # ✅ Keep DateTimeIndex\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def binary_xgb(X_train, Y_train):\n",
    "    yb_train = (Y_train > 0).astype(int)\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb.fit(X_train, yb_train)\n",
    "    yfit_train = xgb.predict_proba(X_train)[:, 1]\n",
    "    return yfit_train\n",
    "\n",
    "def quantile_regression(X, Y, q):\n",
    "    mod = sm.QuantReg(Y, sm.add_constant(X)).fit(q=q)\n",
    "    return mod.params\n",
    "\n",
    "def reconstruct_rain(X, coefs):\n",
    "    return X @ coefs[1:] + coefs[0]\n",
    "\n",
    "def cqm_pipeline(X_train, Y_train, X_test, thresholds):\n",
    "    yfit_train = binary_xgb(X_train, Y_train)\n",
    "    coefs2 = {}\n",
    "    rain_final = {}\n",
    "\n",
    "    for label, t in thresholds.items():\n",
    "        q_val = float(label.replace('p', '')) / 100\n",
    "        mask1 = yfit_train > t\n",
    "        X1, Y1 = X_train[mask1], Y_train[mask1]\n",
    "        if X1.empty or Y1.empty:\n",
    "            continue\n",
    "        coef1 = quantile_regression(X1, Y1, q_val)\n",
    "        rain1 = reconstruct_rain(X1, coef1)\n",
    "        mask2 = rain1 > 0\n",
    "        X2, Y2 = X1[mask2], Y1[mask2]\n",
    "        if X2.empty or Y2.empty:\n",
    "            continue\n",
    "        coef2 = quantile_regression(X2, Y2, q_val)\n",
    "        coefs2[label] = coef2\n",
    "        rain_test = reconstruct_rain(X_test, coef2)\n",
    "        rain_final[label] = np.maximum(rain_test, 0)\n",
    "\n",
    "    return coefs2, rain_final\n",
    "\n",
    "def compute_cqvss(y_true, y_pred_model, y_pred_ref, q):\n",
    "    errors_m = y_true - y_pred_model\n",
    "    errors_r = y_true - y_pred_ref\n",
    "    ql_m = np.mean(np.maximum(q * errors_m, (q - 1) * errors_m))\n",
    "    ql_r = np.mean(np.maximum(q * errors_r, (q - 1) * errors_r))\n",
    "    return 1 - (ql_m / ql_r) if ql_r != 0 else np.nan\n",
    "\n",
    "# === CONFIG ===\n",
    "\n",
    "pca_folder = r'D:\\D\\Ruvision\\GFS\\Pickle format\\PKL'\n",
    "obs_excel = pd.read_excel(\n",
    "    'C:/Users/Angshudeep Majumdar/Documents/Angshudeep Lappy/Ruvision/IMD_2015-2024_Daily Data_0.25 resolution Rain_GFS.xlsx'\n",
    ")\n",
    "output_base = r'D:/D/Ruvision/plots/GFS/XGBoost'\n",
    "\n",
    "thresholds = {'80p': 0.2, '85p': 0.15, '90p': 0.1, '95p': 0.05, '99p': 0.01}\n",
    "quantiles = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "all_conf_matrices=[]\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "\n",
    "for pkl in glob.glob(os.path.join(pca_folder, '*.pkl')):\n",
    "    var_comb = os.path.basename(pkl).split('transformed_dataX_')[1].split('.pkl')[0]\n",
    "    out_dir = os.path.join(output_base, var_comb)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # === Load data ===\n",
    "    X, Y_df = load_data(pkl, obs_excel)\n",
    "    Y = Y_df['Prec_23.0_72.5']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X, Y)\n",
    "\n",
    "    # === CQM ===\n",
    "    coefs2, rain_final = cqm_pipeline(X_train, Y_train, X_test, thresholds)\n",
    "    \n",
    "    # === SQM ===\n",
    "    sqm_models = []\n",
    "    for q in quantiles:\n",
    "        mod = sm.QuantReg(Y_train, sm.add_constant(X_train)).fit(q=q, max_iter=5000)\n",
    "        sqm_models.append(mod)\n",
    "\n",
    "    sqm_final = {}\n",
    "    for i, q in enumerate(quantiles):\n",
    "        rain_q = sqm_models[i].predict(sm.add_constant(X_test))\n",
    "        rain_q = np.maximum(rain_q, 0)\n",
    "        sqm_final[f\"{int(q*100)}p\"] = pd.Series(rain_q, index=X_test.index)\n",
    "\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    lr = LinearRegression().fit(X_train, Y_train)\n",
    "    pred_lr_all = lr.predict(X_test)\n",
    "    pred_lr_all = pd.Series(pred_lr_all, index=X_test.index)\n",
    "\n",
    "    # === JJAS ===\n",
    "    jjas_start = pd.Timestamp('2024-06-02')\n",
    "    jjas_end = pd.Timestamp('2024-09-28')\n",
    "    mask_jjas = (Y_test.index >= jjas_start) & (Y_test.index <= jjas_end)\n",
    "    Y_jjas = Y_test[mask_jjas]\n",
    "    # === Filter SQM for JJAS ===\n",
    "    sqm_final_jjas = {}\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label in sqm_final:\n",
    "            sqm_final_jjas[q_label] = sqm_final[q_label][mask_jjas]\n",
    "   \n",
    "    pred_lr_jjas = pred_lr_all[mask_jjas]\n",
    "    test_index = Y_test.index\n",
    "\n",
    "    rain_final_jjas = {k: pd.Series(v, index=X_test.index)[mask_jjas] for k, v in rain_final.items()}\n",
    "\n",
    "    threshold_value = np.percentile(Y_jjas, 95)\n",
    "    y_true = np.array(Y_jjas)\n",
    "    y_pred_ref = np.array(pred_lr_jjas)\n",
    "\n",
    "    results = []\n",
    "    reports=[]\n",
    "    for q in quantiles:\n",
    "        q_label = f\"{int(q * 100)}p\"\n",
    "        if q_label not in rain_final_jjas or q_label not in sqm_final_jjas:\n",
    "            continue\n",
    "\n",
    "        y_pred_cqm = rain_final_jjas[q_label].values\n",
    "        y_pred_sqm = sqm_final_jjas[q_label].values\n",
    "        obs_bin = y_true > threshold_value\n",
    "        pred_bin_cqm = y_pred_cqm > threshold_value\n",
    "        pred_bin_sqm = y_pred_sqm > threshold_value\n",
    "        pred_bin_lr = y_pred_ref > threshold_value\n",
    "\n",
    "        H = np.sum((obs_bin == 1) & (pred_bin_cqm == 1))\n",
    "        M = np.sum((obs_bin == 1) & (pred_bin_cqm == 0))\n",
    "        FA = np.sum((obs_bin == 0) & (pred_bin_cqm == 1))\n",
    "        CN = np.sum((obs_bin == 0) & (pred_bin_cqm == 0))\n",
    "\n",
    "        POD = H / (H + M) if (H + M) > 0 else np.nan\n",
    "        FAR = FA / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        Accuracy = (H + CN) / (H + M + FA + CN) if (H + M + FA + CN) > 0 else np.nan\n",
    "        Precision = H / (H + FA) if (H + FA) > 0 else np.nan\n",
    "        F1 = 2 * (Precision * POD) / (Precision + POD) if (Precision + POD) > 0 else np.nan\n",
    "        TS = H / (H + M + FA) if (H + M + FA) > 0 else np.nan\n",
    "        BIAS = (H + FA) / (H + M) if (H + M) > 0 else np.nan\n",
    "        denom = ((H + M) * (M + CN)) + ((H + FA) * (FA + CN))\n",
    "        HSS = (2 * (H * CN - FA * M)) / denom if denom != 0 else np.nan\n",
    "        corr, _ = pearsonr(y_true, y_pred_cqm)\n",
    "        cqvss = compute_cqvss(y_true, y_pred_cqm, y_pred_ref, q)\n",
    "\n",
    "        H_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 1))\n",
    "        M_LR = np.sum((obs_bin == 1) & (pred_bin_lr == 0))\n",
    "        FA_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 1))\n",
    "        CN_LR = np.sum((obs_bin == 0) & (pred_bin_lr == 0))\n",
    "        POD_LR = H_LR / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        FAR_LR = FA_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        Accuracy_LR = (H_LR + CN_LR) / (H_LR + M_LR + FA_LR + CN_LR) if (H_LR + M_LR + FA_LR + CN_LR) > 0 else np.nan\n",
    "        Precision_LR = H_LR / (H_LR + FA_LR) if (H_LR + FA_LR) > 0 else np.nan\n",
    "        F1_LR = 2 * (Precision_LR * H_LR) / (Precision_LR + H_LR) if (Precision_LR + H_LR) > 0 else np.nan\n",
    "        TS_LR = H_LR / (H_LR + M_LR + FA_LR) if (H_LR + M_LR + FA_LR) > 0 else np.nan\n",
    "        BIAS_LR = (H_LR + FA_LR) / (H_LR + M_LR) if (H_LR + M_LR) > 0 else np.nan\n",
    "        corr_LR, _ = pearsonr(y_true, y_pred_ref)\n",
    "        \n",
    "        H_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 1))\n",
    "        M_SQM = np.sum((obs_bin == 1) & (pred_bin_sqm == 0))\n",
    "        FA_SQM = np.sum((obs_bin == 0) & (pred_bin_sqm == 1))\n",
    "        CN_SQM= np.sum((obs_bin == 0) & (pred_bin_sqm == 0))\n",
    "        POD_SQM = H_SQM / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        FAR_SQM = FA_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        Accuracy_SQM = (H_SQM + CN_SQM) / (H_SQM + M_SQM + FA_SQM + CN_SQM) if (H_SQM + M_SQM + FA_SQM + CN_SQM) > 0 else np.nan\n",
    "        Precision_SQM = H_SQM / (H_SQM + FA_SQM) if (H_SQM + FA_SQM) > 0 else np.nan\n",
    "        F1_SQM = 2 * (Precision_SQM * H_SQM) / (Precision_SQM + H_SQM) if (Precision_SQM + H_SQM) > 0 else np.nan\n",
    "        TS_SQM = H_SQM / (H_SQM + M_SQM + FA_SQM) if (H_SQM + M_SQM + FA_SQM) > 0 else np.nan\n",
    "        BIAS_SQM = (H_SQM + FA_SQM) / (H_SQM + M_SQM) if (H_SQM + M_SQM) > 0 else np.nan\n",
    "        denom_SQM = ((H_SQM + M_SQM) * (M_SQM + CN_SQM)) + ((H_SQM + FA_SQM) * (FA_SQM + CN_SQM))\n",
    "        HSS_SQM = (2 * (H_SQM * CN_SQM - FA_SQM * M_SQM)) / denom_SQM if denom_SQM != 0 else np.nan\n",
    "        corr_sqm, _ = pearsonr(y_true, y_pred_sqm)\n",
    "        cqvss_sqm = compute_cqvss(y_true, y_pred_sqm, y_pred_ref, q)\n",
    "\n",
    "        results.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H, 'Misses_CQM': M, 'False Alarms_CQM': FA, 'Correct Negatives_CQM': CN,\n",
    "            'Correlation_CQM': round(corr, 3),\n",
    "            'Hit Rate_CQM': round(POD, 3),\n",
    "            'False Alarm Ratio_CQM': round(FAR, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'F1 Score_CQM': round(F1, 3),\n",
    "            'Threat Score_CQM': round(TS, 3),\n",
    "            'Bias Score_CQM': round(BIAS, 3),\n",
    "            'Heidke Skill Score_CQM': round(HSS, 3),\n",
    "            'CQVSS_CQM': round(cqvss, 3),\n",
    "            'Hit Rate_LR': round(POD_LR, 3),\n",
    "            'False Alarm Ratio_LR': round(FAR_LR, 3),\n",
    "            'Accuracy_LR': round(Accuracy_LR, 3),\n",
    "            'Precision_LR': round(Precision_LR, 3),\n",
    "            'F1 Score_LR': round(F1_LR, 3),\n",
    "            'Threat Score_LR': round(TS_LR, 3),\n",
    "            'Bias_LR': round(BIAS_LR, 3),\n",
    "            'Correlation_LR':round(corr_LR,3),\n",
    "            'Hits_SQM': H_SQM, 'Misses_SQM': M_SQM, 'False Alarms_SQM': FA_SQM,\n",
    "            'Correlation_SQM': round(corr_sqm, 3),\n",
    "            'Hit Rate_SQM': round(POD_SQM, 3),\n",
    "            'False Alarm Ratio_SQM': round(FAR_SQM, 3),\n",
    "            'Accuracy_SQM': round(Accuracy_SQM, 3),\n",
    "            'Precision_SQM': round(Precision_SQM, 3),\n",
    "            'F1 Score_SQM': round(F1_SQM, 3),\n",
    "            'Threat Score_SQM': round(TS_SQM, 3),\n",
    "            'Bias_SQM': round(BIAS_SQM, 3),\n",
    "            'Heidke Skill Score_SQM': round(HSS_SQM, 3),\n",
    "            'SQVSS_SQM': round(cqvss_sqm, 3)\n",
    "            \n",
    "        })\n",
    "\n",
    "        reports.append({\n",
    "            'Quantile': q,\n",
    "            'Hits_CQM': H,\n",
    "            'Misses_CQM': M,\n",
    "            'False Alarms_CQM': FA,\n",
    "            'Correct Negatives_CQM': CN,\n",
    "            'Recall_CQM': round(POD, 3),\n",
    "            'Precision_CQM': round(Precision, 3),\n",
    "            'Accuracy_CQM': round(Accuracy, 3),\n",
    "            'F1 Score_CQM': round(F1, 3)\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(results).to_excel(os.path.join(out_dir, 'contingency_matrix.xlsx'), index=False)\n",
    "\n",
    "    conf_matrix = pd.DataFrame([\n",
    "        {\n",
    "            'Variable_Combination': var_comb,\n",
    "            **r\n",
    "        } for r in reports\n",
    "    ])\n",
    "    all_conf_matrices.append(conf_matrix)\n",
    "\n",
    "    # === SAVE FINAL CONCATENATED CONFUSION MATRIX ===\n",
    "\n",
    "    if all_conf_matrices:\n",
    "        final_df = pd.concat(all_conf_matrices, ignore_index=True)\n",
    "        final_df.to_excel(r'C:\\Users\\Angshudeep Majumdar\\Downloads\\all_confusion_matrices.xlsx', index=False)\n",
    "\n",
    "    # === Plots stay same, but now use sqm_final_jjas ===\n",
    "\n",
    "    # === CQM Plots ===\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in rain_final: continue\n",
    "        cqm_jjas = pd.Series(rain_final[q_label], index=test_index)[mask_jjas]\n",
    "        r, _ = pearsonr(Y_jjas, cqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, cqm_jjas))\n",
    "        axs[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs[i].plot(cqm_jjas.index, cqm_jjas, label=f'CQM Q{q}', color='red')\n",
    "        axs[i].set_title(f'CQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "        axs[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'XGB based CQR Model Experiment | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.savefig(os.path.join(out_dir, f'CQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # === SQM Plots ===\n",
    "    fig2, axs2 = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "    for i, q in enumerate(quantiles):\n",
    "        q_label = f\"{int(q*100)}p\"\n",
    "        if q_label not in sqm_final_jjas: continue\n",
    "        sqm_jjas = sqm_final_jjas[q_label]\n",
    "        r, _ = pearsonr(Y_jjas, sqm_jjas)\n",
    "        rmse = np.sqrt(mean_squared_error(Y_jjas, sqm_jjas))\n",
    "        axs2[i].plot(Y_jjas.index, Y_jjas, label='Obs', color='blue')\n",
    "        axs2[i].plot(sqm_jjas.index, sqm_jjas, label=f'SQM Q{q}', color='green')\n",
    "        axs2[i].set_title(f'SQM Q{q} | r={r:.2f} | RMSE={rmse:.2f}')\n",
    "        axs2[i].tick_params(axis='x', rotation=45)\n",
    "        axs2[i].legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'SQM Prediction | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig2.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig2.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig2.savefig(os.path.join(out_dir, f'SQM_QuantilePlots_{var_comb}.png'))\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # === Skill Score Plots ===\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    x_labels = [f\"{int(q)}p\" for q in metrics_df['Quantile'] * 100]\n",
    "\n",
    "    fig3, axs3 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs3[0].bar(x_labels, metrics_df['Hit Rate_CQM'], color='red'); axs3[0].set_title('Hit Rate (POD)')\n",
    "    axs3[1].bar(x_labels, metrics_df['False Alarm Ratio_CQM'], color='orange'); axs3[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs3[2].bar(x_labels, metrics_df['Threat Score_CQM'], color='blue'); axs3[2].set_title('Threat Score (TS)')\n",
    "    axs3[3].bar(x_labels, metrics_df['Bias Score_CQM'], color='purple'); axs3[3].set_title('Bias Score')\n",
    "    axs3[4].bar(x_labels, metrics_df['Heidke Skill Score_CQM'], color='green'); axs3[4].set_title('HSS')\n",
    "    axs3[5].bar(x_labels, metrics_df['CQVSS_CQM'], color='pink'); axs3[5].set_title('CQVSS')\n",
    "    fig3.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_XGB based CQR Model Experiment', fontsize=16)\n",
    "    fig3.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig3.savefig(os.path.join(out_dir, f'CQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig3)\n",
    "\n",
    "    fig4, axs4 = plt.subplots(1, 6, figsize=(30, 6))\n",
    "    axs4[0].bar(x_labels, metrics_df['Hit Rate_SQM'], color='red'); axs4[0].set_title('Hit Rate (POD)')\n",
    "    axs4[1].bar(x_labels, metrics_df['False Alarm Ratio_SQM'], color='orange'); axs4[1].set_title('False Alarm Ratio (FAR)')\n",
    "    axs4[2].bar(x_labels, metrics_df['Threat Score_SQM'], color='blue'); axs4[2].set_title('Threat Score (TS)')\n",
    "    axs4[3].bar(x_labels, metrics_df['Bias_SQM'], color='purple'); axs4[3].set_title('Bias Score')\n",
    "    axs4[4].bar(x_labels, metrics_df['Heidke Skill Score_SQM'], color='green'); axs4[4].set_title('HSS')\n",
    "    axs4[5].bar(x_labels, metrics_df['SQVSS_SQM'], color='pink'); axs4[5].set_title('SQVSS')\n",
    "    fig4.suptitle(f'Verification Metrics for Extreme Events (Obs > 95th Percentile = 40.29mm)_{var_comb}_SQM', fontsize=16)\n",
    "    fig4.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig4.savefig(os.path.join(out_dir, f'SQM_SkillScores_Bar_{var_comb}.png'))\n",
    "    plt.close(fig4)\n",
    "\n",
    "    # === Linear Regression ===\n",
    "    fig5, ax5 = plt.subplots(figsize=(15, 6))\n",
    "    r_lr, _ = pearsonr(Y_jjas, pred_lr_jjas)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(Y_jjas, pred_lr_jjas))\n",
    "    ax5.plot(Y_jjas.index, Y_jjas, label='Observed', color='blue')\n",
    "    ax5.plot(pred_lr_jjas.index, pred_lr_jjas, label='Linear Regression', color='black')\n",
    "    ax5.set_title(f'Linear Regression | {var_comb} | JJAS | r={r_lr:.2f} | RMSE={rmse_lr:.2f}', fontsize=14)\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.legend()\n",
    "    # Lat-lon text\n",
    "    lat_range = (22.5, 23.5)\n",
    "    lon_range = (72, 73)\n",
    "\n",
    "    # Combine with \\n for a multi-line suptitle\n",
    "    main_title = f'Linear Regression | {var_comb} | JJAS'\n",
    "    lat_lon_text = f'Location: Lat {lat_range[0]}°–{lat_range[1]}°, Lon {lon_range[0]}°–{lon_range[1]}°'\n",
    "    fig5.suptitle(f'{main_title}\\n{lat_lon_text}', fontsize=16)\n",
    "    fig5.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig5.savefig(os.path.join(out_dir, f'LinearRegression_{var_comb}_JJAS.png'))\n",
    "    plt.close(fig5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f31858-842d-45b1-bcba-29aeb41bc949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
